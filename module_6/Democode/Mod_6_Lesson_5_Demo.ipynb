{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU1aC6rnTYDy"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cm-int/classification_models/blob/main/module_6/Democode/Mod_6_Lesson_5_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKcnoSITfjiL"
      },
      "source": [
        "#Selecting Model Features and Algorithms\n",
        "\n",
        "In this demonstration, you’ll create a classification model based on a raw dataset and measure the precision and recall. You’ll refine the dataset by selecting and scaling features and assess the impact this has on the performance of the model. You'll also examine how the choice of algorithm can affect the results.\n",
        "\n",
        "This demonstration uses the Airline Passenger Satisfaction dataset.\n",
        "\n",
        "**Note:** This dataset is a cleaned-up and modified version of the original 'Passenger Satisfaction' dataset published on Kaggle.\n",
        "\n",
        "##Context\n",
        "This dataset contains an airline passenger satisfaction survey. What factors are highly correlated to a satisfied (or dissatisfied) passenger? Can you predict passenger satisfaction?\n",
        "\n",
        "##Features:\n",
        "\n",
        "- *Gender*: Gender of the passengers (Female, Male)\n",
        "\n",
        "- *Customer Type*: The customer type (Loyal customer, disloyal customer)\n",
        "\n",
        "- *Age*: The actual age of the passenger\n",
        "\n",
        "- *Type of Travel*: Purpose of the flight (Personal Travel, Business Travel)\n",
        "\n",
        "- *Class*: Travel class (Business, Eco, Eco Plus)\n",
        "\n",
        "- *Flight distance*: The flight distance of this journey\n",
        "\n",
        "- *Inflight wifi service*: Satisfaction level of the inflight wifi service (0:Not Applicable;1-5)\n",
        "\n",
        "- *Departure/Arrival time convenient*: Satisfaction level of Departure/Arrival time convenience (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Ease of Online booking*: Satisfaction level of online booking (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Gate location*: Satisfaction level of Gate location (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Food and drink*: Satisfaction level of Food and drink (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Online boarding*: Satisfaction level of online boarding (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Seat comfort*: Satisfaction level of Seat comfort (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Inflight entertainment*: Satisfaction level of inflight entertainment (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *On-board service*: Satisfaction level of On-board service (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Leg room service*: Satisfaction level of Leg room service (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Baggage handling*: Satisfaction level of baggage handling (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Check-in service*: Satisfaction level of Check-in service (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Inflight service*: Satisfaction level of inflight service (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Cleanliness*: Satisfaction level of Cleanliness (0:Completely dissatisfied;5:Completely satisfied)\n",
        "\n",
        "- *Departure Delay in Minutes*: Minutes delayed on departure\n",
        "\n",
        "- *Arrival Delay in Minutes*: Minutes delayed on Arrival\n",
        "\n",
        "#Target Class:\n",
        "\n",
        "- *Satisfaction:* Overall satisfaction level(Not Satisfied/Neutral or Satisfied)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UB-LN6w-bl-v"
      },
      "outputs": [],
      "source": [
        "# Upload the customer_satisfaction.csv file\n",
        "\n",
        "!wget 'https://raw.githubusercontent.com/cm-int/classification_models/main/module_6/Democode/customer_satisfaction.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6Nb9P9-c8mS"
      },
      "outputs": [],
      "source": [
        "# Read the data from the CSV file\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "customer_satisfaction = pd.read_csv(\"customer_satisfaction.csv\")\n",
        "print(f'{customer_satisfaction.info()}\\n\\n')\n",
        "customer_satisfaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNOkRM2Vdetn"
      },
      "outputs": [],
      "source": [
        "# Separate the class variable ('satisfaction') from the features and convert the categorical features into dummy variables\n",
        "features = customer_satisfaction.drop(['satisfaction'], axis=1)\n",
        "features = pd.get_dummies(features)\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9wFz9-deqHr"
      },
      "outputs": [],
      "source": [
        "# Convert the class label (not satisfied/satisfied) into a numeric value (0/1)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "satisfaction_class = customer_satisfaction['satisfaction']\n",
        "cat_encoder = LabelEncoder().fit(satisfaction_class)\n",
        "satisfaction_class = cat_encoder.transform(satisfaction_class)\n",
        "\n",
        "print(satisfaction_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtfpsd6pfFlY"
      },
      "outputs": [],
      "source": [
        "# Split the data into test and training datasets, build a K-Nearest Neighbors model, and test the precision, recall, and AUC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "\n",
        "features_train, features_test, class_train, class_test = train_test_split(features, satisfaction_class, test_size=0.33, random_state=13)\n",
        "\n",
        "knn_model = KNeighborsClassifier() # Select default hyperparameters (n_neighbors=5)\n",
        "_ = knn_model.fit(features_train, class_train)\n",
        "\n",
        "test_results = knn_model.predict(features_test)\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(class_test, test_results,  display_labels=['Not Satisfied', 'Satisfied'])\n",
        "\n",
        "print(f'Precision: {precision_score(class_test, test_results)}')\n",
        "print(f'Recall: {recall_score(class_test, test_results)}\\n')\n",
        "\n",
        "_ = RocCurveDisplay.from_predictions(class_test, test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w0S6CMXf1a5"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "\n",
        "How good is this model at predicting a positive outcome?\n",
        "\n",
        "*Answer: Poor. The model misses many positive outcomes and reports them as negatives. Additionally, it misclassifies a large percentage of negative outcomes as positives*.\n",
        "\n",
        "*This is the baseline for further investigation.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_TkYh3_f75v"
      },
      "source": [
        "# Perform a SHAP analysis to examine which features have the most effect on the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTurbLW5f-QB"
      },
      "outputs": [],
      "source": [
        "# Install the SHAP module\n",
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8jwlSJpgFWt"
      },
      "outputs": [],
      "source": [
        "# Create a SHAP explainer to analyze predictions made using the model\n",
        "# NOTE: This step takes 5 minutes to run\n",
        "\n",
        "import shap\n",
        "import random\n",
        "\n",
        "items = random.sample(list(features_train.index), 50) # The analysis is restricted to 50 random observations to save time\n",
        "explainer_train = features_train[features_train.index.isin(items)]\n",
        "\n",
        "explainer = shap.Explainer(knn_model.predict, explainer_train)\n",
        "values = explainer(explainer_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdquDgwwg1NS"
      },
      "outputs": [],
      "source": [
        "# Display the results as a summary plot\n",
        "\n",
        "shap.summary_plot(shap_values=values, features=explainer_train, plot_type=\"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AELYr1Jkg6DG"
      },
      "outputs": [],
      "source": [
        "# The violin plot indicateshow the features are correlated with the predictions\n",
        "\n",
        "shap.summary_plot(shap_values=values, features=explainer_train, plot_type=\"violin\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "enlkU8Nzg8Uv"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "What does this analysis indicate?\n",
        "\n",
        "*Answer: Most of the features have little to no bearing on the predictions. It would appear that the most important features are flight distance, age, arrival delay, and departure delay. The flight distance feature is a bit of a surprise - why should the length of the flight be important? This could possibly be due to passengers feeling tired after a long flight, but further analysis is necessary to verify these findings*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH_wMjpfhCdB"
      },
      "source": [
        "# Perform a multivariate search to find the most important features for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIcNe20fhEHT"
      },
      "outputs": [],
      "source": [
        "# Perform a forward selection search using the SelectKBest function\n",
        "# NOTE: This step takes 5 or 6 minutes to run\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "# Iterate over the best models with different sized feature sets \n",
        "# and calculate the precision and recall of each model\n",
        "\n",
        "pr_scores = []\n",
        "rc_scores = []\n",
        "for k in range(1, len(features_train.columns)-1):\n",
        "    features_selector = SelectKBest(score_func=chi2, k=k)\n",
        "    features_selector = features_selector.fit(features_train, class_train)\n",
        "    print(features_selector.get_feature_names_out())\n",
        "    transformed_train = features_selector.transform(features_train)\n",
        "    transformed_test = features_selector.transform(features_test)\n",
        "    model = KNeighborsClassifier()\n",
        "    model.fit(transformed_train, class_train)\n",
        "    predictions = model.predict(transformed_test)\n",
        "    pr_score = metrics.precision_score(class_test, predictions, zero_division=0, average='macro')\n",
        "    pr_scores.append(pr_score)\n",
        "    rc_score = metrics.recall_score(class_test, predictions, zero_division=0, average='macro')\n",
        "    rc_scores.append(rc_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wsRqsqJiBny"
      },
      "outputs": [],
      "source": [
        "# Plot the results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(40, 10))\n",
        "plt.plot(range(1, len(features_train.columns)-1), pr_scores, label='Precision')\n",
        "plt.plot(range(1, len(features_train.columns)-1), rc_scores, label='Recall')\n",
        "plt.xlabel('\\nBest K Features', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "plt.xticks(range(1, len(features_train.columns)-1))\n",
        "plt.ylabel('Precision/Recall Scores', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "plt.legend(prop={'size': 20})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y29TNOSAiJCu"
      },
      "outputs": [],
      "source": [
        "# Find the best precision score to minimize the false positive rate \n",
        "# (use recall to minimize the false negative rate)\n",
        "\n",
        "best_score = max(pr_scores)\n",
        "num_features = np.where(pr_scores == best_score)[0][0]\n",
        "features_selector = SelectKBest(score_func=chi2, k=num_features+1)\n",
        "features_selector = features_selector.fit(features_train, class_train)\n",
        "best_features = features_selector.get_feature_names_out()\n",
        "print(f'Best features: {best_features}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO4jhp10ntwE"
      },
      "source": [
        "**Question::**\n",
        "\n",
        "How do these findings compare to the SHAP analysis?\n",
        "\n",
        "*Answer: Flight distance is still the most significant feature, but age has dropped out. Unsurprisingly departure delay and arrival delay are still important.* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnsxlWM0nwkl"
      },
      "source": [
        "#Build and test a model using the *'best'* set of features "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzhSILWhnsWW"
      },
      "outputs": [],
      "source": [
        "best_features_train = features_train[best_features]\n",
        "\n",
        "best_features_test = features_test[best_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwDfd02voR9u"
      },
      "outputs": [],
      "source": [
        "knn_model = KNeighborsClassifier() \n",
        "_ = knn_model.fit(best_features_train, class_train)\n",
        "\n",
        "test_results = knn_model.predict(best_features_test)\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(class_test, test_results, display_labels=['Not Satisfied', 'Satisfied'])\n",
        "\n",
        "print(f'Precision: {precision_score(class_test, test_results)}')\n",
        "print(f'Recall: {recall_score(class_test, test_results)}\\n')\n",
        "\n",
        "_ = RocCurveDisplay.from_predictions(class_test, test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCBKuGQ6og-s"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "Has the model improved?\n",
        "\n",
        "*Answer: Slightly. Precision and recall are marginally improved, but still a bit low.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJxM5dBLN2zV"
      },
      "source": [
        "#Examine how scaling affects the choice of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqP9PMfpONy2"
      },
      "outputs": [],
      "source": [
        "# Return to the original dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "customer_satisfaction = pd.read_csv(\"customer_satisfaction.csv\")\n",
        "\n",
        "# Separate the class variable ('satisfaction') from the features and convert the categorical features into dummy variables\n",
        "\n",
        "features = customer_satisfaction.drop(['satisfaction'], axis=1)\n",
        "\n",
        "# Convert the class label (not satisfied/satisfied) into a numeric value (0/1)\n",
        "\n",
        "satisfaction_class = customer_satisfaction['satisfaction']\n",
        "cat_encoder = LabelEncoder().fit(satisfaction_class)\n",
        "satisfaction_class = cat_encoder.transform(satisfaction_class)\n",
        "print(satisfaction_class)\n",
        "\n",
        "# Split the data into test and training datasets, build a K-Nearest Neighbors model, and test the precision, recall, and AUC\n",
        "\n",
        "features_train, features_test, class_train, class_test = train_test_split(features, satisfaction_class, test_size=0.33, random_state=13)\n",
        "\n",
        "print(features_train.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXHuoBujPs3q"
      },
      "outputs": [],
      "source": [
        "# Create a pipeline to perform encoding of the categorical features and scaling of the numeric features\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import set_config\n",
        "\n",
        "numeric_features = features_train.select_dtypes(include='number').columns\n",
        "categorical_features = features_train.select_dtypes(include='object').columns\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_preprocessor = Pipeline([('categorical_encoder', OneHotEncoder())])\n",
        "\n",
        "# Clean and scale numeric features\n",
        "numeric_preprocessor = Pipeline([('replace_nan', SimpleImputer(missing_values=np.nan, strategy='mean')),\\\n",
        "                                 ('numeric_scaler', StandardScaler())])\n",
        "\n",
        "# Apply transformations to categorical and numeric columns as appropriate\n",
        "pipeline_preprocessor = ColumnTransformer([('numeric_preprocessor', numeric_preprocessor, numeric_features), \\\n",
        "                       ('categorical_preprocessor', categorical_preprocessor, categorical_features)])\n",
        "\n",
        "# Create the pipeline and fit a K-Nearest Neighbours model\n",
        "pipe = Pipeline([('preprocessor', pipeline_preprocessor),\n",
        "                 ('estimator', KNeighborsClassifier())])\n",
        "\n",
        "pipe.fit(features_train, class_train)\n",
        "\n",
        "# Display the details of the pipe\n",
        "set_config(display=\"diagram\")\n",
        "pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytAsPM83YLpF"
      },
      "outputs": [],
      "source": [
        "# Display the names of the features generated by the pipeline\n",
        "numeric_feature_names = pipe['preprocessor'].transformers_[0][1]['numeric_scaler'].get_feature_names_out(numeric_features)\n",
        "print(f'Numeric features: {numeric_feature_names}\\n')\n",
        "\n",
        "categorical_feature_names = pipe['preprocessor'].transformers_[1][1]['categorical_encoder'].get_feature_names_out(categorical_features)\n",
        "print(f'Categorical features: {categorical_feature_names}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnLRpK4cYpLe"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "\n",
        "# Make test predictions\n",
        "predictions = pipe.predict(features_test)\n",
        "\n",
        "# Check the precision and recall\n",
        "pr_score = metrics.precision_score(class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = metrics.recall_score(class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(class_test, predictions, display_labels=['Not Satisifed', 'Satisifed'])\n",
        "_ = RocCurveDisplay.from_predictions(class_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjCHCdJDZIy4"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "Has the model improved?\n",
        "\n",
        "*Answer: Precision, recall, and AUC are all much better. Scaling has had a significant impact on the quality of the model*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQJbtayAZMB1"
      },
      "source": [
        "#Perform SHAP analysis on the new model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z95NsBxDZPt1"
      },
      "outputs": [],
      "source": [
        "# Run the pipeline again without the estimator to get the transformed training data\n",
        "transformed_features_train = pd.DataFrame(pipe[0].transform(features_train))\n",
        "transformed_features_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hE_ym7kPZZ3R"
      },
      "outputs": [],
      "source": [
        "# The feature names have been lost, so reinstate them from the lists seen earlier\n",
        "new_names = np.append(numeric_feature_names, categorical_feature_names)\n",
        "transformed_features_train.columns = new_names\n",
        "transformed_features_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiAeQzKVZj52"
      },
      "outputs": [],
      "source": [
        "# Perform SHAP analysis over the transformed training data\n",
        "# NOTE: Allow 5 or 6 minutes for this step to complete\n",
        "# NOTE 2: Ignore the warnings about the classifier not being fitted with feature names\n",
        "\n",
        "import shap\n",
        "import random\n",
        "\n",
        "items = random.sample(list(transformed_features_train.index), 50) # As before, the analysis is restricted to the 50 random observations to save time\n",
        "explainer_train = transformed_features_train[transformed_features_train.index.isin(items)]\n",
        "\n",
        "explainer = shap.Explainer(pipe['estimator'].predict, explainer_train) # Perform the analysis using the 'estimator' object from the pipeline\n",
        "values = explainer(explainer_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFwD1VsaZtAV"
      },
      "outputs": [],
      "source": [
        "# Display the results\n",
        "shap.summary_plot(shap_values=values, features=explainer_train, plot_type=\"bar\")\n",
        "shap.summary_plot(shap_values=values, features=explainer_train, plot_type=\"violin\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8CvceYquZxUz"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "What does this analysis tell us?\n",
        "\n",
        "*Answer: Scaling the numeric features results in more features having a greater influence in the model predictions. Flight distance, which previously had the largest numeric value, has now dropped down the list of importance. Customer satisfaction now seems to be more influenced by features such as inflight wifi, ease of boarding, cleanliness, inflight entertainment, seat comfort, and on-board service.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUSY00YyaA_4"
      },
      "source": [
        "#Perform multivariate forward selection with the new model and assess whether this change improves predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eA2wKonaEUM"
      },
      "outputs": [],
      "source": [
        "# Use the SequentialFeatureSelector to find the best set of features for the model\n",
        "# NOTE: This step takes approximately 6 minutes to run\n",
        "\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "\n",
        "features_to_select = 5\n",
        "\n",
        "sfs_forward = SequentialFeatureSelector(pipe['estimator'], n_features_to_select=features_to_select, direction=\"forward\")\n",
        "sfs_forward.fit(transformed_features_train, class_train)\n",
        "\n",
        "print(f\"Features selected by forward sequential selection: {sfs_forward.get_feature_names_out()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lCzYNykaJFY"
      },
      "outputs": [],
      "source": [
        "# Transform the test data and rename the columns\n",
        "\n",
        "transformed_features_test = pd.DataFrame(pipe[0].transform(features_test))\n",
        "transformed_features_test.columns = new_names\n",
        "transformed_features_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp3fnvz1aMLq"
      },
      "outputs": [],
      "source": [
        "# Build a new model using only the selected features\n",
        "reduced_features_train = transformed_features_train[sfs_forward.get_feature_names_out()]\n",
        "reduced_features_test = transformed_features_test[sfs_forward.get_feature_names_out()]\n",
        "\n",
        "knn_model = KNeighborsClassifier() # Create a new classifier\n",
        "_ = knn_model.fit(reduced_features_train, class_train)\n",
        "\n",
        "test_results = knn_model.predict(reduced_features_test)\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(class_test, test_results, display_labels=['No', 'Yes'])\n",
        "\n",
        "print(f'Precision: {precision_score(class_test, test_results)}')\n",
        "print(f'Recall: {recall_score(class_test, test_results)}\\n')\n",
        "\n",
        "_ = RocCurveDisplay.from_predictions(class_test, test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-laW96iaPHj"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "How does this model fare?\n",
        "\n",
        "*Answer: Focussing on a smaller number of columns reduced the precision and recall slightly, so this might not be the best strategy in this case*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHyc5BGNdxDr"
      },
      "source": [
        "# Perform detailed multivariate forward selection and select the features more carefully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trHadUKKd0ez"
      },
      "outputs": [],
      "source": [
        "# Perform another forward selection search using the SelectKBest function and evaluate the best mix of features for precision and recall\n",
        "# NOTE: This step takes 5 or 6 minutes to run\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "import sklearn.metrics as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Iterate over the best models with different sized feature sets \n",
        "# and calculate the precision and recall of each model\n",
        "\n",
        "pr_scores = []\n",
        "rc_scores = []\n",
        "for k in range(1, len(transformed_features_train.columns)-1):\n",
        "    features_selector = SelectKBest(score_func=f_classif, k=k)\n",
        "    features_selector = features_selector.fit(transformed_features_train, class_train)\n",
        "    print(features_selector.get_feature_names_out())\n",
        "    transformed_train = features_selector.transform(transformed_features_train)\n",
        "    transformed_test = features_selector.transform(transformed_features_test)\n",
        "    model = KNeighborsClassifier()\n",
        "    model.fit(transformed_train, class_train)\n",
        "    predictions = model.predict(transformed_test)\n",
        "    pr_score = metrics.precision_score(class_test, predictions, zero_division=0, average='macro')\n",
        "    pr_scores.append(pr_score)\n",
        "    rc_score = metrics.recall_score(class_test, predictions, zero_division=0, average='macro')\n",
        "    rc_scores.append(rc_score)\n",
        "\n",
        "# Plot the results\n",
        "\n",
        "plt.figure(figsize=(40, 10))\n",
        "plt.plot(range(1, len(transformed_features_train.columns)-1), pr_scores, label='Precision')\n",
        "plt.plot(range(1, len(transformed_features_train.columns)-1), rc_scores, label='Recall')\n",
        "plt.xlabel('\\nBest K Features', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "plt.xticks(range(1, len(transformed_features_train.columns)-1))\n",
        "plt.ylabel('Precision/Recall Scores', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "plt.legend(prop={'size': 20})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B19ITm_Qd8ZT"
      },
      "outputs": [],
      "source": [
        "# Find the features for the best precision score to minimize the false positive rate \n",
        "# (use recall to minimize the false negative rate)\n",
        "best_score = max(pr_scores)\n",
        "num_features = np.where(pr_scores == best_score)[0][0]\n",
        "features_selector = SelectKBest(score_func=f_classif, k=num_features+1)\n",
        "features_selector = features_selector.fit(transformed_features_train, class_train)\n",
        "print(f'Best features: {features_selector.get_feature_names_out()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqT5UdTed_gs"
      },
      "outputs": [],
      "source": [
        "# Build another new model using only the selected features\n",
        "reduced_features_train = transformed_features_train[features_selector.get_feature_names_out()]\n",
        "reduced_features_test = transformed_features_test[features_selector.get_feature_names_out()]\n",
        "\n",
        "knn_model = KNeighborsClassifier() # Create a new classifier\n",
        "_ = knn_model.fit(reduced_features_train, class_train)\n",
        "\n",
        "test_results = knn_model.predict(reduced_features_test)\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(class_test, test_results, display_labels=['Not Satisfied', 'Satisfied'])\n",
        "\n",
        "print(f'Precision: {precision_score(class_test, test_results)}')\n",
        "print(f'Recall: {recall_score(class_test, test_results)}\\n')\n",
        "\n",
        "_ = RocCurveDisplay.from_predictions(class_test, test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzbTuXK5eDxZ"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "Is this model an improvement?\n",
        "\n",
        "*Answer: Selecting features based on model precision yields an improvement, at the cost of a small reduction in recall.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tuWVmbkowHm"
      },
      "source": [
        "#Try using feature extraction as an alternative strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5xZSzs3ozo-"
      },
      "outputs": [],
      "source": [
        "# Return to the original dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "customer_satisfaction = pd.read_csv(\"customer_satisfaction.csv\")\n",
        "\n",
        "# Separate the class variable ('satisfaction') from the features and convert the categorical features into dummy variables\n",
        "\n",
        "features = customer_satisfaction.drop(['satisfaction'], axis=1)\n",
        "features = pd.get_dummies(features)\n",
        "\n",
        "# Convert the class label (not satisfied/satisfied) into a numeric value (0/1)\n",
        "\n",
        "satisfaction_class = customer_satisfaction['satisfaction']\n",
        "cat_encoder = LabelEncoder().fit(satisfaction_class)\n",
        "satisfaction_class = cat_encoder.transform(satisfaction_class)\n",
        "print(satisfaction_class)\n",
        "\n",
        "print(features.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2mI5VubpsmK"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Perform PCA analysis\n",
        "pca = PCA()\n",
        "pca.fit(features)\n",
        "\n",
        "print(pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eDzHagBpxYU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10,10))\n",
        "x = np.arange(1, len(pca.explained_variance_)+1)\n",
        "plt.bar(x, pca.explained_variance_ratio_)\n",
        "plt.xlabel('Principal Components', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "plt.ylabel('Proportion of Explained Variances', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8UZP_a2p1YR"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "Which component(s) account for the most variance?\n",
        "\n",
        "*Answer: Component 1 accounts for 99.9% of the variance. This component dwarfs the variance of the other components. Try building a model with this single component.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_1xiqT5qAZ5"
      },
      "outputs": [],
      "source": [
        "# Construct another model using the first principal component only\n",
        "pca_data = pd.DataFrame(pca.transform(features))\n",
        "component_data = pca_data.iloc[:, 0:1]\n",
        "\n",
        "# Split the data into test and training datasets\n",
        "pca_train, pca_test, pca_class_train, pca_class_test = train_test_split(component_data, satisfaction_class, test_size=0.33, random_state=13)\n",
        "\n",
        "# Build the model\n",
        "pca_knn_model = KNeighborsClassifier()\n",
        "pca_knn_model.fit(pca_train, pca_class_train)\n",
        "predictions = pca_knn_model.predict(pca_test)\n",
        "\n",
        "# Check the precision and recall\n",
        "pr_score = precision_score(pca_class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = recall_score(pca_class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(pca_class_test, predictions, display_labels=['Not Satisfied', 'Satisfied'])\n",
        "_ = RocCurveDisplay.from_predictions(pca_class_test, test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuccgWCvrLCE"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "Is this model an improvement?\n",
        "\n",
        "*Answer: Precision and Recall have dropped significantly, as has the AUC. Compacting the predictive power into a single component was probably optimistic.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63GP83tBram_"
      },
      "outputs": [],
      "source": [
        "# Try again with the first ten principal components\n",
        "pca_data = pd.DataFrame(pca.transform(features))\n",
        "component_data = pca_data.iloc[:, 0:10]\n",
        "\n",
        "# Split the data into test and training datasets\n",
        "pca_train, pca_test, pca_class_train, pca_class_test = train_test_split(component_data, satisfaction_class, test_size=0.33, random_state=13)\n",
        "\n",
        "# Build the model\n",
        "pca_knn_model = KNeighborsClassifier()\n",
        "pca_knn_model.fit(pca_train, pca_class_train)\n",
        "predictions = pca_knn_model.predict(pca_test)\n",
        "\n",
        "# Check the precision and recall\n",
        "pr_score = precision_score(pca_class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = recall_score(pca_class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(pca_class_test, predictions, display_labels=['Not Satisfied', 'Satisfied'])\n",
        "_ = RocCurveDisplay.from_predictions(pca_class_test, test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geun_S1csXfd"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "Is this model an improvement?\n",
        "\n",
        "*Answer: Precision and Recall have improved. Maybe there is more information in the other components than is alluded to by their variance.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5SPwSD3saKQ"
      },
      "source": [
        "#Compare PCA to t-SNE\n",
        "\n",
        "**NOTE:** t-SNE analysis of the data takes upwards of 15 minutes. Only do this part if time allows, otherwise go straight to UMAP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeT6sKlmsdx6"
      },
      "outputs": [],
      "source": [
        "# Return to the original dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "customer_satisfaction = pd.read_csv(\"customer_satisfaction.csv\")\n",
        "\n",
        "# Separate the class variable ('satisfaction') from the features and convert the categorical features into dummy variables\n",
        "\n",
        "features = customer_satisfaction.drop(['satisfaction'], axis=1)\n",
        "features = pd.get_dummies(features)\n",
        "\n",
        "# Convert the class label (not satisfied/satisfied) into a numeric value (0/1)\n",
        "\n",
        "satisfaction_class = customer_satisfaction['satisfaction']\n",
        "cat_encoder = LabelEncoder().fit(satisfaction_class)\n",
        "satisfaction_class = cat_encoder.transform(satisfaction_class)\n",
        "print(satisfaction_class)\n",
        "\n",
        "print(features.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caxwXIz5tKcW"
      },
      "outputs": [],
      "source": [
        "# NOTE: Allow 15 minutes for this step\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Perform t-SNE analysis\n",
        "tsne = TSNE(n_components=3) # Reduce the dataset to 3 dimensions\n",
        "transformed_data = tsne.fit_transform(features)\n",
        "tsne_features = transformed_data[:, 0:2]\n",
        "\n",
        "# Split the data into test and training datasets\n",
        "tsne_features_train, tsne_features_test, tsne_class_train, tsne_class_test = train_test_split(tsne_features, satisfaction_class, test_size=0.33, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76bkcXvjuSTV"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "\n",
        "# Build a model using the new dataset\n",
        "\n",
        "tsne_knn_model = KNeighborsClassifier()\n",
        "tsne_knn_model.fit(tsne_features_train, tsne_class_train)\n",
        "predictions = tsne_knn_model.predict(tsne_features_test)\n",
        "\n",
        "# Check the precision and recall\n",
        "pr_score = precision_score(tsne_class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = recall_score(tsne_class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(tsne_class_test, predictions, display_labels=['Not Satisfied', 'Satisfied'])\n",
        "_ = RocCurveDisplay.from_predictions(tsne_class_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdYxTkm9ud5S"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "How does performance compare to PCA?\n",
        "\n",
        "*Answer: Precision and Recall are comparable to PCA with a single component, but are not as good as PCA with ten components. AUC is poor. You could possibly tune by experimenting with the perplexity and learning rate, but it is a time-consuming process.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzV1TJaWumN8"
      },
      "source": [
        "#Try UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEC2HO3IuhvH"
      },
      "outputs": [],
      "source": [
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdeagJXOu50c"
      },
      "outputs": [],
      "source": [
        "# Return to the original dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "customer_satisfaction = pd.read_csv(\"customer_satisfaction.csv\")\n",
        "\n",
        "# Separate the class variable ('satisfaction') from the features and convert the categorical features into dummy variables\n",
        "\n",
        "features = customer_satisfaction.drop(['satisfaction'], axis=1)\n",
        "features = pd.get_dummies(features)\n",
        "\n",
        "# Convert the class label (not satisfied/satisfied) into a numeric value (0/1)\n",
        "\n",
        "satisfaction_class = customer_satisfaction['satisfaction']\n",
        "cat_encoder = LabelEncoder().fit(satisfaction_class)\n",
        "satisfaction_class = cat_encoder.transform(satisfaction_class)\n",
        "print(satisfaction_class)\n",
        "\n",
        "print(features.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VjLWSxrvXAM"
      },
      "outputs": [],
      "source": [
        "# Perform UMAP analysis\n",
        "import umap.umap_ as umap\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "reducer = umap.UMAP(n_neighbors=7, n_components=7) # Experiment with different values\n",
        "umap_features = reducer.fit_transform(features)\n",
        "\n",
        "# Split the data into test and training datasets\n",
        "umap_features_train, umap_features_test, umap_class_train, umap_class_test = train_test_split(umap_features, satisfaction_class, test_size=0.33, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqwl2MEpxbLu"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "\n",
        "# Build a model using the new dataset\n",
        "\n",
        "umap_knn_model = KNeighborsClassifier()\n",
        "umap_knn_model.fit(umap_features_train, umap_class_train)\n",
        "predictions = umap_knn_model.predict(umap_features_test)\n",
        "\n",
        "# Check the precision and recall\n",
        "pr_score = precision_score(umap_class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = recall_score(umap_class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(umap_class_test, predictions, display_labels=['Not Satisfied', 'Satisfied'])\n",
        "_ = RocCurveDisplay.from_predictions(umap_class_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTl4Nby8ni86"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "How does performance compare to PCA and t-SNE?\n",
        "\n",
        "*Answer: In this example, the performance of the UMAP model lies between that of PCA with ten components and t-SNE.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjKDBqL3oFcM"
      },
      "source": [
        "#Incorporate scaling with PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-JkVWYlDkTc"
      },
      "source": [
        "*PCA appears to be the most appropriate feature extraction technique for this dataset, and scaling had a significant impact. The next logical step is to try combining these two approaches. This will involve the use of a pipeline.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkbTL9zXoJqU"
      },
      "outputs": [],
      "source": [
        "# Return to the original dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "customer_satisfaction = pd.read_csv(\"customer_satisfaction.csv\")\n",
        "\n",
        "# Separate the class variable ('satisfaction') from the features and convert the categorical features into dummy variables\n",
        "\n",
        "features = customer_satisfaction.drop(['satisfaction'], axis=1)\n",
        "features = pd.get_dummies(features)\n",
        "\n",
        "# Convert the class label (not satisfied/satisfied) into a numeric value (0/1)\n",
        "\n",
        "satisfaction_class = customer_satisfaction['satisfaction']\n",
        "cat_encoder = LabelEncoder().fit(satisfaction_class)\n",
        "satisfaction_class = cat_encoder.transform(satisfaction_class)\n",
        "print(satisfaction_class)\n",
        "\n",
        "print(features_train.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98Pb1-qaoZAW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into test and training datasets\n",
        "features_train, features_test, class_train, class_test = train_test_split(features, satisfaction_class, test_size=0.33, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSsQHlo-o77I"
      },
      "outputs": [],
      "source": [
        "# Try scaling before performing PCA.\n",
        "# Construct a new pipeline that includes feature extraction\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import set_config\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "numeric_features = features_train.select_dtypes(include='number').columns\n",
        "categorical_features = features_train.select_dtypes(include='object').columns\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_preprocessor = Pipeline([('categorical_encoder', OneHotEncoder())])\n",
        "\n",
        "# Clean and scale numeric features\n",
        "numeric_preprocessor = Pipeline([('replace_nan', SimpleImputer(missing_values=np.nan, strategy='mean')),\\\n",
        "                                 ('numeric_scaler', StandardScaler())])\n",
        "\n",
        "# Apply transformations to categorical and numeric columns as appropriate\n",
        "pipeline_preprocessor = \\\n",
        "    ColumnTransformer([('numeric_preprocessor', numeric_preprocessor, numeric_features), \\\n",
        "                       ('categorical_preprocessor', categorical_preprocessor, categorical_features)])\n",
        "\n",
        "# Create the pipeline with PCA and fit a K-Nearest Neighbors model\n",
        "pca_pipe = Pipeline([('preprocessor', pipeline_preprocessor),\n",
        "                     ('extractor', PCA(n_components=1)), # Only generate the first PCA component\n",
        "                     ('estimator', KNeighborsClassifier())])\n",
        "\n",
        "pca_pipe.fit(features_train, class_train)\n",
        "\n",
        "# Display the details of the pipe\n",
        "set_config(display=\"diagram\")\n",
        "pca_pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_khWEEVvpOmT"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "predictions = pca_pipe.predict(features_test)\n",
        "\n",
        "# Check the precision and recall\n",
        "pr_score = precision_score(class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = recall_score(class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(class_test, predictions, display_labels=['Not Satisfied', 'Satisfied'])\n",
        "_ = RocCurveDisplay.from_predictions(class_test, test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGp3P6b_pq1R"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "How does this model compare to previously?\n",
        "\n",
        "*Answer: Precision and Recall are better than PCA alone, but not as good as scaling without PCA.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUWerWMPptfe"
      },
      "outputs": [],
      "source": [
        "# Try again with a single principal component (this was the initial fit for PCA earlier)\n",
        "pca_pipe[1].set_params(**{'n_components': 1})\n",
        "\n",
        "pca_pipe.fit(features_train, class_train)\n",
        "predictions = pca_pipe.predict(features_test)\n",
        "pr_score = precision_score(class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = recall_score(class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(class_test, predictions, display_labels=['No', 'Yes'])\n",
        "_ = RocCurveDisplay.from_predictions(class_test, test_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkXhbnKuqmq3"
      },
      "outputs": [],
      "source": [
        "# And again, this time with ten principal components\n",
        "pca_pipe[1].set_params(**{'n_components': 10})\n",
        "\n",
        "pca_pipe.fit(features_train, class_train)\n",
        "predictions = pca_pipe.predict(features_test)\n",
        "pr_score = precision_score(class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = recall_score(class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(class_test, predictions, display_labels=['No', 'Yes'])\n",
        "_ = RocCurveDisplay.from_predictions(class_test, test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyHDpTr_qzZ0"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "How about now?\n",
        "\n",
        "*Answer: Precision and Recall have improved, but are still below that achieved by using scaling alone.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV74H7IFq26k"
      },
      "source": [
        "# Try multivariate feature selection to ascertain how selecting multiple PCA components affects the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUi0jiTYrIan"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "import sklearn.metrics as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Run the pipeline again to generate all PCA components\n",
        "pca_pipe[1].set_params(**{'n_components': None})\n",
        "pca_pipe.fit(features_train, class_train)\n",
        "\n",
        "# Generate the transformed data using the pipeline\n",
        "pca_data = pd.DataFrame(pca_pipe[:-1].transform(features))\n",
        "\n",
        "# Rename the columns returned by PCA analysis - the existing column names are numeric which can cause problems. Prepend each name with an 'x'\n",
        "pca_column_names = [f'x%d' % i for i in pca_data.columns]\n",
        "pca_data = pca_data.set_axis(pca_column_names, axis=1)\n",
        "\n",
        "# Split the data into training and test datasets\n",
        "pca_train, pca_test, pca_class_train, pca_class_test = train_test_split(pca_data, satisfaction_class, test_size=0.33, random_state=13)\n",
        "num_rows, num_cols = pca_data.shape\n",
        "\n",
        "# Iterate over the best models with different sized feature sets \n",
        "# and calculate the precision and recall of each model\n",
        "\n",
        "pr_scores = []\n",
        "rc_scores = []\n",
        "for k in range(1, num_cols-1):\n",
        "    features_selector = SelectKBest(score_func=f_classif, k=k)\n",
        "    features_selector = features_selector.fit(pca_train, pca_class_train)\n",
        "    print(features_selector.get_feature_names_out())\n",
        "    transformed_train = features_selector.transform(pca_train)\n",
        "    transformed_test = features_selector.transform(pca_test)\n",
        "    model = KNeighborsClassifier()\n",
        "    model.fit(transformed_train, class_train)\n",
        "    predictions = model.predict(transformed_test)\n",
        "    pr_score = metrics.precision_score(pca_class_test, predictions, zero_division=0, average='macro')\n",
        "    pr_scores.append(pr_score)\n",
        "    rc_score = metrics.recall_score(pca_class_test, predictions, zero_division=0, average='macro')\n",
        "    rc_scores.append(rc_score)\n",
        "\n",
        "# Plot the results\n",
        "\n",
        "plt.figure(figsize=(40, 10))\n",
        "plt.plot(range(1, num_cols-1), pr_scores, label='Precision')\n",
        "plt.plot(range(1, num_cols-1), rc_scores, label='Recall')\n",
        "plt.xlabel('\\nBest K Features', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "plt.xticks(range(1, num_cols-1))\n",
        "plt.ylabel('Precision/Recall Scores', fontdict={'family': 'serif','color':  'darkred','weight': 'normal','size': 28})\n",
        "plt.legend(prop={'size': 20})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YBg84QHrhk6"
      },
      "outputs": [],
      "source": [
        "# Find the features for the best precision score to minimize the false positive rate \n",
        "# (use recall, rc_scores, to minimize the false negative rate)\n",
        "\n",
        "best_score = max(pr_scores)\n",
        "num_features = np.where(pr_scores == best_score)[0][0]\n",
        "features_selector = SelectKBest(score_func=f_classif, k=num_features+1)\n",
        "features_selector = features_selector.fit(pca_train, pca_class_train)\n",
        "best_features = features_selector.get_feature_names_out()\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "print(f'Best features: {best_features}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Poo5bYJgrqW6"
      },
      "outputs": [],
      "source": [
        "# Construct another model using the highlighted principal components\n",
        "# Note: This test doesn't use the pipeline or perform scaling\n",
        "\n",
        "pca_knn_model = KNeighborsClassifier()\n",
        "pca_knn_model.fit(pca_train[best_features], pca_class_train)\n",
        "predictions = pca_knn_model.predict(pca_test[best_features])\n",
        "\n",
        "# Check the precision and recall\n",
        "pr_score = metrics.precision_score(pca_class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = metrics.recall_score(pca_class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(pca_class_test, predictions, display_labels=['Not Satisfied', 'Satisfied'])\n",
        "_ = RocCurveDisplay.from_predictions(pca_class_test, test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1rUTBLjsEiL"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "Is this an improvement?\n",
        "\n",
        "*Answer: Precision and Recall have improved signifcantly. However, the model is still only comparable to that which used scaling without PCA*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYEedN3NsMHO"
      },
      "source": [
        "#Try different algorithms - Logistic Regression and Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2CTQ40ZsR_O"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Change the K-Nearest Neigbors estimator in the PCA pipeline for a Logistic Regression estimator\n",
        "pca_pipe.set_params(**{'estimator': LogisticRegression(max_iter=1000, solver=\"lbfgs\", tol=1e-3)})\n",
        "pca_pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffug24GRsogO"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "from sklearn.metrics import precision_score, recall_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "\n",
        "# Fit the model \n",
        "pca_pipe.fit(features_train, class_train)\n",
        "\n",
        "# Make predictions\n",
        "predictions = pca_pipe.predict(features_test)\n",
        "\n",
        "# Check the precision and recall\n",
        "pr_score = precision_score(class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = recall_score(class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(class_test, predictions, display_labels=['Not Satisfied', 'Satisfied'])\n",
        "_ = RocCurveDisplay.from_predictions(class_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYZ7wi0FwirZ"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "How does this model compare with those seen so far?\n",
        "\n",
        "*Answer: This model is OK, but not as good as the KNN model with scaling.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk4I4zPTwmgY"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Return to the original dataset\n",
        "customer_satisfaction = pd.read_csv(\"customer_satisfaction.csv\")\n",
        "\n",
        "# Separate the class variable ('satisfaction') from the features and convert the categorical features into dummy variables\n",
        "features = customer_satisfaction.drop(['satisfaction'], axis=1)\n",
        "#features = pd.get_dummies(features)\n",
        "\n",
        "# Convert the class label (not satisfied/satisfied) into a numeric value (0/1)\n",
        "satisfaction_class = customer_satisfaction['satisfaction']\n",
        "cat_encoder = LabelEncoder().fit(satisfaction_class)\n",
        "satisfaction_class = cat_encoder.transform(satisfaction_class)\n",
        "print(satisfaction_class)\n",
        "\n",
        "print(features_train.info())\n",
        "\n",
        "# Split the data into test and training datasets\n",
        "features_train, features_test, class_train, class_test = train_test_split(features, satisfaction_class, test_size=0.33, random_state=13)\n",
        "\n",
        "# Define a new pipeline that selects all features and doesn't scale the numeric data (Tree models are not sensitive to scaling)\n",
        "categorical_features = features_train.select_dtypes(include='object').columns\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_preprocessor = Pipeline([('categorical_encoder', OneHotEncoder())])\n",
        "\n",
        "# Apply transformations to categorical and numeric columns as appropriate\n",
        "pipeline_preprocessor = ColumnTransformer([('categorical_preprocessor', categorical_preprocessor, categorical_features)])\n",
        "\n",
        "# Create the pipeline fit a Random Forest model\n",
        "forest_pipe = Pipeline([('preprocessor', pipeline_preprocessor),\n",
        "                        ('estimator', RandomForestClassifier())])\n",
        "\n",
        "forest_pipe.fit(features_train, class_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTH9KAcMy1Uz"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "from sklearn.metrics import precision_score, recall_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "\n",
        "# Make predictions\n",
        "predictions = forest_pipe.predict(features_test)\n",
        "\n",
        "# Check the precision and recall\n",
        "pr_score = precision_score(class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = recall_score(class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(class_test, predictions, display_labels=['Not Satisfied', 'Satisfied'])\n",
        "_ = RocCurveDisplay.from_predictions(class_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9XiOv95y83H"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "How does this model compare to the KNN and Logistic Regression models?\n",
        "\n",
        "*Answer: This model has a poorer performance than those built by using KNN and Logistic Regression. However, this model has not been tuned to the same extent as the KNN model, so improvements may be possible.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbeumrB9y__h"
      },
      "source": [
        "#Try stacking to reduce bias and variance across multiple algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MS5I2s5azEDM"
      },
      "outputs": [],
      "source": [
        "# Create a stack with pipelines for Random Forest, K-Nearest Neighbors, and Naive Bayes estimators. Use Logistic Regression to aggregate the results\n",
        "# NOTE: Allow 5 minutes to run this step\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create a new pipeline for K-Nearest Neighbors that generates dummy values for categorical data and scale the numeric features\n",
        "numeric_features = features_train.select_dtypes(include='number').columns\n",
        "categorical_features = features_train.select_dtypes(include='object').columns\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_preprocessor = Pipeline([('categorical_encoder', OneHotEncoder())])\n",
        "\n",
        "# Clean and scale numeric features\n",
        "numeric_preprocessor = Pipeline([('replace_nan', SimpleImputer(missing_values=np.nan, strategy='mean')),\\\n",
        "                                 ('numeric_scaler', StandardScaler())])\n",
        "\n",
        "# Apply transformations to categorical and numeric columns as appropriate\n",
        "pipeline_preprocessor = ColumnTransformer([('numeric_preprocessor', numeric_preprocessor, numeric_features), \\\n",
        "                       ('categorical_preprocessor', categorical_preprocessor, categorical_features)])\n",
        "\n",
        "# Create a similar pipeline for Naive Bayes\n",
        "nb_pipe =  Pipeline([('preprocessor', pipeline_preprocessor),\n",
        "                     ('estimator', GaussianNB())])\n",
        "\n",
        "# An another for KNN\n",
        "knn_pipe = Pipeline([('preprocessor', pipeline_preprocessor),\n",
        "                     ('estimator', KNeighborsClassifier())])\n",
        "\n",
        "# Create a stack comprising the random forest pipeline from the previous tasks and the KNN and Naive Bayes pipelines.\n",
        "# The default aggregator at the top of the stack uses Logistic Regression\n",
        "\n",
        "estimators = [\n",
        "    (\"rf\", forest_pipe),\n",
        "    (\"nb\", nb_pipe),\n",
        "    (\"knn\", knn_pipe)\n",
        "]\n",
        "\n",
        "sc = StackingClassifier(estimators=estimators)\n",
        "\n",
        "sc.fit(features_train, class_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM_CjsGVzusY"
      },
      "outputs": [],
      "source": [
        "# Evaluate the stacked model\n",
        "from sklearn.metrics import precision_score, recall_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "\n",
        "# Make predictions\n",
        "predictions = sc.predict(features_test)\n",
        "\n",
        "# Check the precision and recall\n",
        "pr_score = precision_score(class_test, predictions, zero_division=0, average='macro')\n",
        "rc_score = recall_score(class_test, predictions, zero_division=0, average='macro')\n",
        "\n",
        "print(f'Precision is {pr_score}\\nRecall is {rc_score}')\n",
        "\n",
        "_ = ConfusionMatrixDisplay.from_predictions(class_test, predictions, display_labels=['Not Satisfied', 'Satisfied'])\n",
        "_ = RocCurveDisplay.from_predictions(class_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAqLCSRh3K0R"
      },
      "source": [
        "# Conclusion:\n",
        "\n",
        "Feature selection, feature extraction, scaling, and algorithm choice are all important factors to consider when building a machine learning model. It is vitally important that you test and verify the decisions you make. Additionally, you should always consider the possibility of ensemble methods, such as stacking, to help reduce the shortcomings of a particular algorithm when clasifying your data.\n",
        "\n",
        "In this demonstration, the focus has been on raising the Precision and Recall, with scant regard to AUC.\n",
        "\n",
        "It is always important to understand the limitations of a model. Different feature selection and extraction strategies can have an impact (positive and negative) on the model, as can the choice of algorithm."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
